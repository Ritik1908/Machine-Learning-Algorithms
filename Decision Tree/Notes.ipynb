{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decsion Tree:\n",
    "\n",
    "Decsion tree are basically nested if-else structure.\n",
    "<img src = \"etc/img1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pseudo Code:\n",
    "\n",
    "1. Begin with your training dataset, which should have some feature variables and classification or regression output.\n",
    "2. Determine the \"best feature\" in the dataset to split the data.\n",
    "3. Split the data into subsets that contain the correct values for this best feature. This splitting basically defines a node on the tree i.e each node is a splitting point based on a certain feature from our data.\n",
    "4. Recursively generate new tree nodes by using the subset of data created from step 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion:\n",
    "\n",
    "Mathematically speaking, Decision trees use hyperplanes which run parallel to any one of the axes to cut your coordinate system into hyper cuboids."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"etc/terminology.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advantages:\n",
    "1. Intutive and easy to understand.\n",
    "2. Minimal data preparation is required.\n",
    "3. The cost of using the tree for inference is logarithmic in the number of data points used to train the tree.\n",
    "\n",
    "## Disadvantages:\n",
    "1. Overfitting.\n",
    "2. Prone to errors for imbalanced datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Following two concepts are important to understand decision trees:-\n",
    "\n",
    "1. Entropy\n",
    "2. Information Gain\n",
    "\n",
    "### Entropy:\n",
    "In the most layman terms, Entropy is nothing but the measure of disorder. Or you can also call it the measure of purity/impurity.\n",
    "\n",
    "For example:- Entropy of vapour is more than water and ice.\n",
    "\n",
    "In terms of computer science,\n",
    "<img src = \"etc/entropy-example.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entropy of LHS is high because prediction is tough overhere due to more clasfication.\n",
    "\n",
    "### How to calculate Entropy:\n",
    "<img src = \"etc/calculate-entropy.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of how we calculate entropy:\n",
    "\n",
    "It's intutive that Data 1 has more entropy because of more number of choices.\n",
    "<img src = \"etc/calculate-entropy-example.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion:\n",
    "1. More the uncertainity more the entropy.\n",
    "2. For a 2 class problem the min entropy is 0 and the max is 1.\n",
    "3. For more than 3 classes the min entropy is 0 but the max can be greater than 1.\n",
    "4. Base of log doesn't matter in entropy calculation since we are doing comparisions of entropy.\n",
    "\n",
    "### Entropy for continuous (numerical variable):\n",
    "More the peakness of distribution Less the entropy.\n",
    "\n",
    "## Information Gain:\n",
    "Information Gain, is a metric used to train Decision Trees. Specifically, this metric measures the quality of a split. \n",
    "\n",
    "The information gain is based on the decrease in entropy after a data-set is split on an attribute. Constructing a decision tree is all about finding attribute that returns the highest information gain.\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<center>\n",
    "<b>Information Gain = E(Parent) - {Weighted Average} * E(Child)</b>\n",
    "</center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
